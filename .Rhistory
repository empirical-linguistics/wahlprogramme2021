pick <- sample(doors, 1)
open <- sample(doors[which(doors != pick & doors != prize)], 1)
switchyes <- doors[which(doors != pick & doors != open)]
if(pick == prize) (xdata = c(xdata, "noswitch"))
if(switchyes == prize) (xdata = c(xdata, "switch"))
}
table(xdata)
# version in which host doesn't know
# where the car is
xdata <- c()
# version in which host doesn't know
# where the car is
xdata <- c()
for(i in 1:1000) {
prize <- sample(doors, 1)
pick <- sample(doors, 1)
open <- sample(doors[which(doors != pick)], 1)
switchyes <- doors[which(doors != pick & doors != open)]
if(pick == prize) (xdata = c(xdata, "noswitch"))
if(switchyes == prize) (xdata = c(xdata, "switch"))
}
table(xdata)
for(i in 1:1000) {
prize <- sample(doors, 1)
pick <- sample(doors, 1)
open <- sample(doors[which(doors != pick)], 1)
switchyes <- doors[which(doors != pick & doors != open)]
if(pick == prize) (xdata = c(xdata, "noswitch"))
if(switchyes == prize) (xdata = c(xdata, "switch"))
}
table(xdata)
# version in which host doesn't know
# where the car is
xdata <- c()
for(i in 1:1000) {
prize <- sample(doors, 1)
pick <- sample(doors, 1)
open <- sample(doors[which(doors != pick)], 1)
if(open != prize) {
switchyes <- doors[which(doors != pick & doors != open)]
if(pick == prize) (xdata = c(xdata, "noswitch"))
if(switchyes == prize) (xdata = c(xdata, "switch"))
}
}
table(xdata)
for(i in 1:1000) {
prize <- sample(doors, 1)
pick <- sample(doors, 1)
open <- sample(doors[which(doors != pick)], 1)
if(open != prize) {
switchyes <- doors[which(doors != pick & doors != open)]
if(pick == prize) (xdata = c(xdata, "noswitch"))
if(switchyes == prize) (xdata = c(xdata, "switch"))
}
}
table(xdata)
for(i in 1:1000) {
prize <- sample(doors, 1)
pick <- sample(doors, 1)
open <- sample(doors[which(doors != pick)], 1)
if(open != prize) {
switchyes <- doors[which(doors != pick & doors != open)]
if(pick == prize) (xdata = c(xdata, "noswitch"))
if(switchyes == prize) (xdata = c(xdata, "switch"))
}
}
table(xdata)
for(i in 1:1000) {
prize <- sample(doors, 1)
pick <- sample(doors, 1)
open <- sample(doors[which(doors != pick)], 1)
if(open != prize) {
switchyes <- doors[which(doors != pick & doors != open)]
if(pick == prize) (xdata = c(xdata, "noswitch"))
if(switchyes == prize) (xdata = c(xdata, "switch"))
}
}
table(xdata)
for(i in 1:1000) {
prize <- sample(doors, 1)
pick <- sample(doors, 1)
open <- sample(doors[which(doors != pick)], 1)
if(open != prize) {
switchyes <- doors[which(doors != pick & doors != open)]
if(pick == prize) (xdata = c(xdata, "noswitch"))
if(switchyes == prize) (xdata = c(xdata, "switch"))
}
}
table(xdata)
library(rethinking)
N <- 500
income <- c(1,2,5)
score <- 0.5*income
p <- softmax(score[1], score[2], score[3])
?softmax
career <- rep(NA, N)
set.seed(34302)
for(i in 1:N ) career[i] <- sample(1:3, size=1, prob=p)
code_m13.11 <- "
data{
int N; // number of individuals
int K; // number of possible careers
int career[N]; // outcome
vector[K] career_income;
}
parameters{
vector[K-1] a; // intercepts
real<lower=0> b; // association of income with choice
}
model{
vector[K] p;
vector[K] s;
a ~ normal(0,1);
b ~ normal(0,0.5);
s[1] = a[1] + b*career_income[1];
s[2] = a[2] + b*career_income[2];
s[3] = 0; // pivot
p = softmax (s);
career ~ categorical(p);
}
"
# data list
dat_list <- list(N = N, K = 3, career = career, career_income = income)
m11.13 <- stan(model_code = code_m13.11, data = dat_list,
chains = 4)
precis(m11.13, 2)
13430/2
38000/150
?chisq.test
70*3*3
70*5
70*6
library(tidyverse)
d <- data.frame(a = c("sehr lange Variable", "noch längere Variable", "sehr lange Variable"))
?rename
?recode
recode(d$a, "sehr lange Variable" = "sehr lange \n Variable")
recode(d$a, "sehr lange Variable" = "sehr lange \n Variable", "noch längere Variable" = "noch längere \n Variable")
# packages ----------------------------------------------------------------
library(tidyverse)
library(tidytext)
library(pdftools)
library(wordcloud)
library(stopwords)
library(DT)
spd_text <- readRDS("spd.Rds")
cdu_text <- readRDS("cdu.Rds")
csu_text <- readRDS("csu.Rds")
fdp_text <- readRDS("fdp.Rds")
gruene_text <- readRDS("gruene.Rds")
afd_text <- readRDS("afd.Rds")
# packages ----------------------------------------------------------------
library(tidyverse)
library(tidytext)
library(pdftools)
library(wordcloud)
library(stopwords)
library(DT)
setwd("~/sciebo/Projekte/Wahlprogramme")
spd_text <- readRDS("spd.Rds")
cdu_text <- readRDS("cdu.Rds")
csu_text <- readRDS("csu.Rds")
fdp_text <- readRDS("fdp.Rds")
gruene_text <- readRDS("gruene.Rds")
afd_text <- readRDS("afd.Rds")
linke_text <- readRDS("linke.Rds")
# re-import Trafilatura version
linke_trafi <- readRDS("linke_trafi.Rds")
dwds <- read_delim("dwds_kern_frequency_list.txt", delim = "\t", quote = "", col_names = c("Freq", "Token"))
count_tokens <- function(d) {
# Interpunktion und Zeilenumbrüche weg:
d <- gsub("[[:punct:]]|\n", " ", d)
# Tabstopps und mehrere Leerzeichen durch einfache Leerzeichen ersetzen:
d <- gsub("\t| +", " ", d)
# Groß- und Kleinschreibung entfernen:
d <- tolower(d)
# an Leerzeichen splitten, um an die Einzelwörter zu kommen:
d <- unlist(strsplit(d, " "))
# Wörter auszählen:
d <- table(d) %>% as.data.frame %>% arrange(desc(Freq))
# Spaltennamen umbenennen:
colnames(d) <- c("Token", "Freq")
# Wörter ausschließen
d <- d[!grepl("^kapitel$|^seite$|^[:digit:]*$", d$Token),]
# sicherstellen, dass d$Token character ist
d$Token <- as.character(d$Token)
return(d)
}
# Funktion auf die einzelnen Wahlprogramme anwenden:
fdp <- count_tokens(fdp_text)
spd <- count_tokens(spd_text)
afd <- count_tokens(afd_text)
gruene <- count_tokens(gruene_text)
linke <- count_tokens(linke_text)
cdu <- count_tokens(cdu_text)
csu <- count_tokens(csu_text)
# diese Hilfsfunktion berechnet die erwarteten Frequenzen:
exp2x2 <- function(observed) {
return(matrix(
c(
sum(observed[1,]) * sum(observed[,1]) / sum(observed),
sum(observed[2,]) * sum(observed[,1]) / sum(observed),
sum(observed[1,]) * sum(observed[,2]) / sum(observed),
sum(observed[2,]) * sum(observed[,2]) / sum(observed)
),
ncol = 2
))
}
# diese Funktion berechnet die Log-Likelihood Ratio:
llr <- Vectorize(function(freq1, freq2, corpus_size1, corpus_size2) {
observed <- matrix(c(freq1, corpus_size1 - freq1,
freq2, corpus_size2 - freq2),
ncol = 2)
expected <- exp2x2(observed)
return(2 * sum(ifelse(observed > 0, observed * log(observed / expected), 0)))
})
dice <- Vectorize(function(freq1, freq2, corpus_size1, corpus_size2) {
observed <- matrix(c(freq1, corpus_size1 - freq1,
freq2, corpus_size2 - freq2),
ncol = 2)
return(2 * observed[1, 1] / sum(observed[1, 1], observed[1, 2],
observed[1, 1], observed[2, 1]))
})
# Funktion für odds ratio
odds_ratio <- Vectorize(function(freq1, freq2, corpus_size1, corpus_size2) {
observed <- matrix(c(freq1, corpus_size1 - freq1,
freq2, corpus_size2 - freq2),
ncol = 2)
return(
(observed[1,1] / observed[2,1]) / (observed[1,2] / observed[2,2])
)
})
# Wahlprogramme:
gruene_size <- sum(gruene$Freq)
spd_size <- sum(spd$Freq)
fdp_size <- sum(fdp$Freq)
cdu_size <- sum(cdu$Freq)
csu_size <- sum(csu$Freq)
afd_size <- sum(afd$Freq)
linke_size <- sum(linke$Freq)
# DWDS:
dwds_size <- sum(dwds$Freq)
# Spaltennamen ändern, um Gesamtfrequenz von FDP-Frequenz unterscheiden zu können:
colnames(cdu) <- c("Token", "Freq_cdu")
# DWDS-Frequenzen hinzufügen:
cdu <- left_join(cdu, dwds)
# NAs durch 0 ersetzen
cdu <- replace_na(cdu, list(Freq = 0, Freq_cdu = 0))
# Spalte mit Log-Likelihood hinzufügen:
cdu <- cdu %>% mutate(LLR = llr(cdu$Freq_cdu, cdu$Freq, cdu_size, dwds_size))
# Spalte mit Dice hinzufügen:
cdu <- cdu %>% mutate(Dice = dice(cdu$Freq_cdu, cdu$Freq, cdu_size, dwds_size)) %>% arrange(desc(LLR))
# Spalte mit Odds Ratio hinzufügen:
cdu <- cdu %>% mutate(odds_ratio = odds_ratio(cdu$Freq_cdu, cdu$Freq, cdu_size, dwds_size))
# Top 10, nach LLR sortiert (über arrange(desc(LLR)), s.o.)
cdu %>% head(10)
# nach Dice sortieren:
cdu %>% arrange(desc(Dice)) %>% head(10)
association_measures <- function(df) {
# welche Partei ist gerade dran? mit deparse(substitute())
# erhalten wir den Namen der Partei als character string:
partei <- deparse(substitute(df))
# das ist wichtig, weil wir die size-Variable der
# entsprechenden Partei brauchen.
df_size <- get(paste0(partei, "_size"))
# Spaltennamen ändern, um Gesamtfrequenz von df-Frequenz unterscheiden zu können:
colnames(df) <- c("Token", "Freq_df")
# DWDS-Frequenzen hinzufügen:
df <- left_join(df, dwds)
# NAs durch 0 ersetzen
df <- replace_na(df, list(Freq = 0, Freq_df = 0))
# Spalten mit Log-Likelihood, Odds Ratio, Dice und p-Wert hinzufügen:
df <- df %>% mutate(LLR = llr(df$Freq_df, df$Freq, df_size, dwds_size),
odds_ratio = odds_ratio(df$Freq_df, df$Freq, df_size, dwds_size),
Dice = dice(df$Freq_df, df$Freq, df_size, dwds_size),
p = pchisq(LLR, df = 1, lower.tail = FALSE)) %>% arrange(desc(LLR))
# ausgeben
return(df)
}
# auf die einzelnen Parteien angewendet:
spd <- association_measures(spd)
fdp <- association_measures(fdp)
linke <- association_measures(linke)
afd <- association_measures(afd)
gruene <- association_measures(gruene)
csu <- association_measures(csu)
gruene200 <- head(gruene, 200)
fdp200 <- head(fdp, 200)
spd200 <- head(spd, 200)
afd200 <- head(afd, 200)
cdu200 <- head(cdu, 200)
# Top 200
linke200 <- head(filter(linke, !Token %in% c("li", "strong", "div", "p", "class", "ul", "nav", "h2", "nbsp", "accordion", "href", "a", "id", "h3", "aria", "panel", "role", "h4", "56202", "list")), 200)
csu200 <- head(csu, 200)
# Seed setzen, damit immer die gleiche Wolke entsteht
# (da die Anordnung der Wörter zufallsgeneriert ist)
set.seed(1985)
png("wordclouds001.png", width = 6, height = 6, un = "in", res = 300)
par(mfrow = c(4,2))
par(mar = c(.5, .5, .5, .5) + 0.1)
wordcloud(words = gruene200$Token, freq = gruene200$LLR/20, col = "green", scale = c(3, .01))
wordcloud(words = afd200$Token, freq = afd200$LLR/20, col = "blue", scale = c(3, .1), max.words = 250)
wordcloud(words = fdp200$Token, freq = fdp200$LLR/20, col = "yellow3", scale = c(5, .05))
wordcloud(words = cdu200$Token, freq = cdu200$LLR/20, col = "grey50", scale = c(4, .05))
wordcloud(words = filter(csu200, Token != "")$Token, freq = csu200$LLR/20, col = "black", scale = c(4, .05))
wordcloud(words = linke200$Token, freq = fdp200$LLR/20, col = "darkred", scale = c(4, .01))
wordcloud(words = spd200$Token, freq = spd200$LLR/20, col = "red", scale = c(3, .01))
dev.off()
par(mfrow = c(1,1))
par(mar = c(5, 4, 4, 2) + 0.1)
# Funktion, um leere Elemente zu entfernen
no_empty <- function(vec) {
vec <- vec[which(vec!="")]
return(vec)
}
# SPD-Trigramme:
spd_trigrams <- spd_text %>%
# Worttrennung am Zeilenende ersetzen
gsub("\\-\n", "", .) %>%
# Worttrennung entfernen
gsub("\n", " ", .) %>%
# mehrere Leerzeichen durch eins ersetzen
gsub(" +", " ", .) %>%
# an Satzgrenzen aufspalten
strsplit(., split = "\\.|\\?|!") %>%
# vom Listen- ins Vektorformat überführen
unlist %>%
# Leerzeichen am Anfang und Ende der einzelnen Strings entfernen
trimws %>%
# mit der oben definierten Funktion leere Elemente im Vektor entfernen
no_empty %>%
# in Tibble überführen
as_tibble() %>%
# Trigramme
unnest_tokens(trigram, value, token="ngrams", n = 3) %>%
# NAs entfernen
na.omit()
# FDP-Trigramme:
fdp_trigrams <- fdp_text %>% gsub("\\-\n", "", .) %>%  gsub("\n", " ", .) %>% gsub(" +", " ", .) %>% strsplit(., split = "\\.|\\?|!") %>% unlist %>% trimws %>% no_empty %>% as_tibble() %>% unnest_tokens(trigram, value, token="ngrams", n = 3) %>% na.omit
# Linke-Trigramme:
linke_trigrams <- linke_trafi %>% strsplit(., split = "\\.|\\?|!") %>% unlist %>% trimws %>% no_empty %>% as_tibble() %>% unnest_tokens(trigram, value, token="ngrams", n = 3) %>% na.omit
# CDU-Trigramme:
cdu_trigrams <- cdu_text %>% gsub("\\-\n", "", .) %>%  gsub("\n", " ", .) %>% gsub(" +", " ", .) %>% strsplit(., split = "\\.|\\?|!") %>% unlist %>% trimws %>% no_empty %>% as_tibble() %>% unnest_tokens(trigram, value, token="ngrams", n = 3) %>% na.omit
# CSU-Trigramme:
csu_trigrams <- csu_text %>% gsub("\\-\n", "", .) %>%  gsub("\n", " ", .) %>% gsub(" +", " ", .) %>% strsplit(., split = "\\.|\\?|!") %>% unlist %>% trimws %>% no_empty %>% as_tibble() %>% unnest_tokens(trigram, value, token="ngrams", n = 3) %>% na.omit
# AfD-Trigramme:
afd_trigrams <- afd_text %>% gsub("\\-\n", "", .) %>%  gsub("\n", " ", .) %>% gsub(" +", " ", .) %>% strsplit(., split = "\\.|\\?|!") %>% unlist %>% trimws %>% no_empty %>% as_tibble() %>% unnest_tokens(trigram, value, token="ngrams", n = 3) %>% na.omit
# Grüne-Trigramme:
gruene_trigrams <- gruene_text %>% gsub("\\-\n", "", .) %>%  gsub("\n", " ", .) %>% gsub(" +", " ", .) %>% strsplit(., split = "\\.|\\?|!") %>% unlist %>% trimws %>% no_empty %>% as_tibble() %>%  unnest_tokens(trigram, value, token="ngrams", n = 3) %>% na.omit
trigrams <- rbind(mutate(afd_trigrams, Partei = "afd"),
mutate(cdu_trigrams, Partei = "cdu"),
mutate(csu_trigrams, Partei = "csu"),
mutate(fdp_trigrams, Partei = "fdp"),
mutate(gruene_trigrams, Partei = "gruene"),
mutate(linke_trigrams, Partei = "linke"),
mutate(spd_trigrams, Partei = "spd"))
# Trigramme auszählen, pro Parteiprogramm:
tri_count <- trigrams %>% group_by(Partei, trigram) %>% summarise(
Freq = n()
)
# diese Tabelle mit der oben erstellten verbinden:
tri_count <- left_join(tri_count, tri_all)
tri_count$p_value <- numeric(nrow(tri_count))
# Trigramme auszählen, Parteiprogrammunabhängig:
tri_all <- trigrams %>% group_by(trigram) %>% summarise(
Freq_all = n()
)
# neue LLR-Spalte für tri_count-Dataframe:
tri_count$llr <- numeric(nrow(tri_count))
# Trigramme auszählen, pro Parteiprogramm:
tri_count <- trigrams %>% group_by(Partei, trigram) %>% summarise(
Freq = n()
)
# Trigramme auszählen, Parteiprogrammunabhängig:
tri_all <- trigrams %>% group_by(trigram) %>% summarise(
Freq_all = n()
)
# diese Tabelle mit der oben erstellten verbinden:
tri_count <- left_join(tri_count, tri_all)
# neue LLR-Spalte für tri_count-Dataframe:
tri_count$llr <- numeric(nrow(tri_count))
tri_count$p_value <- numeric(nrow(tri_count))
# LLR für jede Partei errechnen:
for(i in 1:length(unique(tri_count$Partei))) {
prt <- unique(tri_count$Partei)[i]
# current df:
df_not_cur <- tri_count[which(tri_count$Partei != prt),]
df_cur <- tri_count[which(tri_count$Partei == prt),]
tri_count[which(tri_count$Partei == prt),]$llr <- llr(freq1 = as.numeric(df_cur$Freq),
freq2 = as.numeric(df_cur$Freq_all),
corpus_size1 = sum(df_cur$Freq),
corpus_size2 = sum(df_not_cur$Freq_all))
# p-Werte hinzufügen:
tri_count[which(tri_count$Partei == prt),]$p_value <- pchisq(tri_count[which(tri_count$Partei == prt),]$llr, df = 1, lower.tail = FALSE)
}
# Normalisierte Frequenz hinzufügen
tri_count$fpmt_all <- numeric(nrow(tri_count))
tri_count$fpmt <- numeric(nrow(tri_count))
for(i in 1:length(unique(tri_count$Partei))) {
tri_count[tri_count$Partei==unique(tri_count$Partei)[i],]$fpmt <- filter(tri_count, Partei == unique(tri_count$Partei)[i])$Freq / nrow(filter(tri_count, Partei != unique(tri_count$Partei)[i]))
}
for(i in 1:length(unique(tri_count$Partei))) {
tri_count[tri_count$Partei==unique(tri_count$Partei)[i],]$fpmt_all <- filter(tri_count, Partei == unique(tri_count$Partei)[i])$Freq / nrow(filter(tri_count, Partei == unique(tri_count$Partei)[i]))
}
# Funktion anwenden
tri_count$odds_ratio <- numeric(nrow(tri_count))
for(i in 1:length(unique(tri_count$Partei))) {
prt = unique(tri_count$Partei)[i]
tri_count[tri_count$Partei==prt,]$odds_ratio <- odds_ratio(freq1 = filter(tri_count, Partei == prt)$Freq,
freq2 = filter(tri_count, Partei == prt)$Freq_all, corpus_size1 = nrow(filter(tri_count, Partei==prt)), corpus_size2 = nrow(filter(tri_count, Partei != prt)))
}
# Funktion, die ausgibt, ob eines von drei Wörtern in Stopwords enthalten ist:
in_stopwords <- Vectorize(function(x) {
x <- unlist(strsplit(x, " "))
return(length(which(x %in% stopwords("de"))))
})
# Funktion benutzen:
tri_count$in_stopwords <- unname(in_stopwords(tri_count$trigram))
# Wir schließen die Trigramme aus,
# die aus Boilerplate-ähnlichem Material bestehen
tri_count <- tri_count[which(!tri_count$trigram %in% c("parteivorstand 2021 seite",
"der spd kapitel", "spd parteivorstand 2021", "zukunftsprogramm der spd", "das zukunftsprogramm der", grep("(^| )kapitel( |$)|(^| )seite( |$)", tri_count$trigram, value = T))),]
# Wir schließen außerdem alle Trigramme aus, die nur aus Ziffern bestehen (bei der AfD sehr häufig, wohl wg. Seitenzahlen)
tri_count <- tri_count[grep("^([[:digit:]]| )+$", tri_count$trigram, invert = T),]
set.seed(1985)
# mit Stopwords:
png("trigram_wcs002a.png", width = 6, height = 6, un = "in", res = 300)
# svglite("trigram_wcs02.svg", width = 6, height = 6)
par(mfrow = c(4,2))
par(mar = c(.5, .5, .5, .5) + 0.1)
wordcloud(filter(tri_count, Partei == "spd")$trigram,
filter(tri_count, Partei == "spd")$llr,
scale = c(1, .001), colors = "red", max.words = 200)
wordcloud(filter(tri_count, Partei == "linke")$trigram,
filter(tri_count, Partei == "linke")$llr,
scale = c(1, .001), colors = "darkred", max.words = 200)
wordcloud(filter(tri_count, Partei == "fdp")$trigram,
filter(tri_count, Partei == "fdp")$llr,
scale = c(4, .2), colors = "yellow3", max.words = 200)
wordcloud(filter(tri_count, Partei == "cdu")$trigram,
filter(tri_count, Partei == "cdu")$llr/2,
scale = c(2, .01), colors = "grey50", max.words = 200)
wordcloud(filter(tri_count, Partei == "csu")$trigram,
filter(tri_count, Partei == "csu")$llr/3,
scale = c(1, .001), colors = "black", max.words = 200)
wordcloud(filter(tri_count, Partei == "gruene")$trigram,
filter(tri_count, Partei == "gruene")$llr,
scale = c(1.5, .01), colors = "green", max.words = 200)
wordcloud(filter(tri_count, Partei == "afd")$trigram,
filter(tri_count, Partei == "afd")$llr,
scale = c(2, .01), colors = "blue", max.words = 200)
dev.off()
par(mar = c(5, 4, 4, 2) + 0.1)
par(mfrow = c(1,1))
# nur ohne Stopwords:
png("trigram_wcs002b.png", width = 6, height = 6, un = "in", res = 300)
# svglite("trigram_wcs02.svg", width = 6, height = 6)
par(mfrow = c(4,2))
par(mar = c(1, 1, 1, 1) + 0.1)
wordcloud(filter(tri_count, Partei == "spd", in_stopwords == 0)$trigram,
filter(tri_count, Partei == "spd", in_stopwords == 0)$llr,
scale = c(1.5, .001), colors = "red", max.words = 200)
wordcloud(filter(tri_count, Partei == "linke", in_stopwords == 0)$trigram,
filter(tri_count, Partei == "linke", in_stopwords == 0)$llr,
scale = c(.5, .00002), colors = "darkred", max.words = 200, min.freq = 1)
wordcloud(filter(tri_count, Partei == "fdp", in_stopwords == 0)$trigram,
filter(tri_count, Partei == "fdp", in_stopwords == 0)$llr,
scale = c(3, .2), colors = "yellow3", max.words = 200)
wordcloud(filter(tri_count, Partei == "cdu", in_stopwords == 0)$trigram,
filter(tri_count, Partei == "cdu", in_stopwords == 0)$llr,
scale = c(.5, .000001), colors = "grey50", max.words = 200)
wordcloud(filter(tri_count, Partei == "csu", in_stopwords == 0)$trigram,           filter(tri_count, Partei == "csu")$llr,
scale = c(2, .01), colors = "black", max.words = 200)
wordcloud(filter(tri_count, Partei == "gruene", in_stopwords==0)$trigram,
filter(tri_count, Partei == "gruene", in_stopwords == 0)$llr,
scale = c(1, .001), colors = "green", min.freq = 1,max.words = 200)
wordcloud(filter(tri_count, Partei == "afd", in_stopwords == 0)$trigram,
filter(tri_count, Partei == "afd", in_stopwords == 0)$llr,
scale = c(1.5, .01), colors = "blue", min.freq = 2.5, max.words = 200)
dev.off()
par(mar = c(5, 4, 4, 2) + 0.1)
par(mfrow = c(1,1))
set.seed(1985)
# mit Stopwords:
png("trigram_wcs002a1.png", width = 6, height = 6, un = "in", res = 800)
# svglite("trigram_wcs02.svg", width = 6, height = 6)
par(mfrow = c(4,2))
par(mar = c(.5, .5, .5, .5) + 0.1)
wordcloud(filter(tri_count, Partei == "spd")$trigram,
filter(tri_count, Partei == "spd")$llr,
scale = c(1, .001), colors = "red", max.words = 200)
wordcloud(filter(tri_count, Partei == "linke")$trigram,
filter(tri_count, Partei == "linke")$llr,
scale = c(1, .001), colors = "darkred", max.words = 200)
wordcloud(filter(tri_count, Partei == "fdp")$trigram,
filter(tri_count, Partei == "fdp")$llr,
scale = c(4, .2), colors = "yellow3", max.words = 200)
wordcloud(filter(tri_count, Partei == "cdu")$trigram,
filter(tri_count, Partei == "cdu")$llr/2,
scale = c(2, .01), colors = "grey50", max.words = 200)
wordcloud(filter(tri_count, Partei == "csu")$trigram,
filter(tri_count, Partei == "csu")$llr/3,
scale = c(1, .001), colors = "black", max.words = 200)
wordcloud(filter(tri_count, Partei == "gruene")$trigram,
filter(tri_count, Partei == "gruene")$llr,
scale = c(1.5, .01), colors = "green", max.words = 200)
wordcloud(filter(tri_count, Partei == "afd")$trigram,
filter(tri_count, Partei == "afd")$llr,
scale = c(2, .01), colors = "blue", max.words = 200)
dev.off()
par(mar = c(5, 4, 4, 2) + 0.1)
par(mfrow = c(1,1))
